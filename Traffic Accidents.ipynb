{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Traffic Accidents Around LA with IBM Cloud SQL Query and PixieDust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a demonstration on how to use IBM Cloud SQL Query in a Jupyter Notebook, and renders the data returned from SQL Query with PixieDust. For more information, see ...\n",
    "\n",
    "To use this notebook, you'll need:\n",
    "\n",
    "- IBM Cloud Object Storage and create a bucket for some data\n",
    "- IBM Cloud SQL Query\n",
    "\n",
    "You'll first need to download the [traffic accident CSV file](https://catalog.data.gov/dataset/traffic-collision-data-from-2010-to-present/resource/643d0e98-5f40-4db3-8427-02641dd05fd9?inner_span=True) and upload it to your Cloud Object Storage (COS) bucket. \n",
    " \n",
    "Now, run the next cell to download the latest versions of ibmcloudsql and PixieDust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip -q install ibmcloudsql\n",
    "!pip install --upgrade pixiedust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import both into the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibmcloudsql\n",
    "import pixiedust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to keep your credentials safe, import `getpass`, which will store your IBM Cloud API Key so it's not visible to people viewing the notebook. You can enter any prompt you'd like as a string. Once you run the cell, a box will appear. Paste your IBM Cloud API Key into the box and hit return. All you have to do is use the variable `cloud_api_key` to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "cloud_api_key = getpass.getpass('Enter your IBM Cloud API Key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next variables contain the SQL Query CRN and the endpoint of the COS bucket generated when provisioning SQL Query. For the CRN, go to your SQL Query service page - you'll be on the **Manage** tab. Under, _REST API_ there is a button **Instance CRN**. Click that to copy the CRN for the service. Then add that to in the quotes below.\n",
    "\n",
    "For the COS endpoint that will contain the SQL Query results, you can use any bucket you'd like; however, SQL Query generates one for you dso we'll use that one. To the endpoint, we've added the suffix `/accidents`. This will be the prefix of all the results that will be CSV files generated by SQL Query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_crn = 'crn%3Av1%3Abluemix%3Apublic%3Asql-query%3Aus-south%3Aa%2Fd9333eaa1345bf35cbec45eaf7048d6b%3Af5ab81ab-4152-4cbf-8376-10204ce5a5a8%3A%3A' \n",
    "sql_cos_endpoint = 'cos://s3.us-south.objectstorage.softlayer.net/sql-f5ab81ab-4152-4cbf-8376-10204ce5a5a8/accicents'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `ibmcloudsql.SQLQuery` with the API Key, CRN, and COS endpoint. You'll then have access to the `run_sql` method to run your SQL queries on the data.  Here `cos://region/bucket_name/data_file` is the table unique resource identifier (equivalent to a table in SQL) that can be a CSV, Parquet, or JSON file. \n",
    "\n",
    "You can also join files together with with an SQL join, or you can use a wildcard on files names like `example-*` to include several files starting with that name.\n",
    "\n",
    "The following query gets the time, area, age (between 20-35), victim sex, and location of accidents between 5pm and 8pm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlClient = ibmcloudsql.SQLQuery(cloud_api_key, sql_crn, sql_cos_endpoint)\n",
    "\n",
    "data_source = \"cos://us-geo/<your_COS_bucket>/Traffic_Collision_Data_from_2010_to_Present.csv\"\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    `Time Occurred` AS time, \n",
    "    `Area Name` AS area, \n",
    "    `Victim Age` AS age, \n",
    "    `Victim Sex` AS sex, \n",
    "    `Location` AS location \n",
    "FROM  {}\n",
    "WHERE \n",
    "    `Time Occurred` >= 1700 AND `Time Occurred` <= 2000 AND \n",
    "    `Victim Age` >= 20 AND `Victim Age` <= 35\n",
    "\"\"\".format(data_source)\n",
    "\n",
    "traffic_collisions = sqlClient.run_sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the query runs, we can look at a sample of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_collisions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL Query can also handle more advanced queries like CTEs (common table expressions). In the following example, the CTE formats the _location_ column of the previous query and divides the coordinates into separate latitude and longitude columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlClient = ibmcloudsql.SQLQuery(cloud_api_key, sql_crn, sql_cos_endpoint)\n",
    "\n",
    "traffic = sqlClient.run_sql(\"\"\"\n",
    "WITH location AS ( \n",
    "    SELECT \n",
    "        id, \n",
    "        cast(split(coordinates, ',')[0] as float) as latitude, \n",
    "        cast(split(coordinates, ',')[1] as float) as longitude \n",
    "    FROM (SELECT \n",
    "            'Dr Number` as id, \n",
    "            regexp_replace(`Location`, '[()]', '') as coordinates \n",
    "        FROM cos://us-geo/<your_COS_bucket>/Traffic_Collision_Data_from_2010_to_Present.csv  \n",
    "    ) \n",
    ") \n",
    "SELECT  \n",
    "    d.`Dr Number` as id, \n",
    "\td.`Date Occurred` as date, \n",
    "    d.`Time Occurred` AS time, \n",
    "    d.`Area Name` AS area, \n",
    "    d.`Victim Age` AS age, \n",
    "    d.`Victim Sex` AS sex, \n",
    "    l.latitude, \n",
    "    l.longitude \n",
    "FROM cos://us-geo/<your_COS_bucket>/Traffic_Collision_Data_from_2010_to_Present.csv AS d \n",
    "    JOIN \n",
    "    location AS l \n",
    "    ON l.id = d.`Dr Number` \n",
    "WHERE \n",
    "    d.`Time Occurred` >= 1700 AND \n",
    "    d.`Time Occurred` <= 2000 AND \n",
    "    d.`Victim Age` >= 20 AND \n",
    "    d.`Victim Age` <= 35 AND \n",
    "    l.latitude != 0.0000 AND \n",
    "    l.latitude != 0.0000\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PixieDust, we can view the locations of these traffic accidents on a map. Select _Map_ as the chart type. Then, drag _latitude_ and _longitude_ to the _Keys_ box and _id_, _age_, _sex_, and _date_ to the _Values_ box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "mapView",
      "keyFields": "latitude,longitude",
      "mapboxtoken": "pk.eyJ1IjoibWFwYm94IiwiYSI6ImNpejY4M29iazA2Z2gycXA4N2pmbDZmangifQ.-g_vE53SD2WrJ6tFX7QHmA",
      "valueFields": "age,sex,date"
     }
    }
   },
   "outputs": [],
   "source": [
    "display(traffic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 with Spark 2.1",
   "language": "python",
   "name": "python3-spark21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
